services:
  rabbitmq:
    # Use the official image with the management plugin (recommended for dev/monitoring)
    image: rabbitmq:3-management
    container_name: rabbitmq
    ports:
      # AMQP port for Python clients to connect (service-to-service communication)
      - "5672:5672"
      # Management web UI port (for viewing queues at http://localhost:15672)
      - "15672:15672"
    environment:
      # Default user and password (Change these in production!)
      RABBITMQ_HOST: '%'
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
    volumes:
      # Persist configuration and message data
      - rabbitmq_data:/var/lib/rabbitmq/
      - rabbitmq_log:/var/log/rabbitmq
    healthcheck:
      # Checks if RabbitMQ is accepting AMQP connections
      test: ["CMD", "rabbitmq-diagnostics", "check_port_connectivity"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - debates_network

  medialoader:
    build: ./components/medialoader
    networks:
      - debates_network
    # Pass in the S3 credentials from your .env files
    environment:
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - S3_BUCKET_NAME=${S3_BUCKET_NAME}
      - S3_MEDIA_PATH=${S3_MEDIA_PATH}
    volumes:
      - ./inputs/media:/app/input
    depends_on:
      minio-setup:
        condition: service_completed_successfully
      rabbitmq:
        condition: service_healthy

  converter:
    build: ./components/converter
    networks:
      - debates_network
    # Pass in the S3 credentials from your .env files
    environment:
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - S3_BUCKET_NAME=${S3_BUCKET_NAME}
    volumes:
      - ./audio-to-process:/app/output
    # Make it dependent on Minio
    depends_on:
      minio-setup:
        condition: service_completed_successfully
      whisper-diarize:
        condition: service_started
      rabbitmq:
        condition: service_healthy

  transcriber:
    build: ./components/transcriber
    networks:
      - debates_network
    environment:
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - S3_BUCKET_NAME=${S3_BUCKET_NAME}
      - HF_TOKEN=${HF_TOKEN}
      - WHISPER_MODEL=${WHISPER_MODEL:-base}
    volumes:
      - ./inputs/transcripts:/app/input
    depends_on:
      whisper-diarize:
        condition: service_started # Use the "service_started" fix from before

  dbloader:
      build:
        context: ./components/dbloader
        dockerfile: Dockerfile
      networks:
        - debates_network
      environment:
        SOLR_URL: http://solr:8983/solr/debates/
        MONGO_URL: mongodb://${MONGO_USER}:${MONGO_PASSWORD}@mongodb-instance:27017/
        MONGO_DB: debates
        S3_SERVER: http://minio-instance:9000
        S3_FRONTEND_BASE_URL: http://localhost:80
        S3_ACCESS_KEY: ${S3_ACCESS_KEY}
        S3_SECRET_KEY: ${S3_SECRET_KEY}
        S3_BUCKET_NAME: ${S3_BUCKET_NAME}
      depends_on:
        - minio-instance
        - mongodb-instance
        - solr
        - rabbitmq

  whisper-diarize:
    image: registry.hf.space/katospiegel-odtp-pyannote-whisper:latest
    platform: linux/amd64
    ports:
      - "7860:7860" # This will be available at http://localhost:7860
    environment:
      - ODTP_API_MODE=TRUE
      - HF_TOKEN=${HF_TOKEN}
    networks:
      - debates_network
    # You might also need these, which are the equivalent of '-it'
    stdin_open: true
    tty: true
